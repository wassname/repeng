{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dde9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4be683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from repeng.train.train_adapter import evaluate_model, load_model, load_labels, TrainingConfig, get_choice_ids, select_dilemma_by_values, load_and_process_daily_dilemmas_eval_dataset, process_daily_dilemma_results, proj_root, register_ipissa_peft, setup_adapter, add_adapter_name_to_sd, train_steer_vector\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98eebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251108_205443\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_062438\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_080729\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_133105\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_210703\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_222644\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_224048\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_225447\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_231923\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_233202\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251109_234647\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_000141\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_001629\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_003103\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_004509\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_011728\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_012947\n",
      "/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters/honest_contrastive_ipissa_20251110_070542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dir = sorted(( proj_root / \"./outputs/adapters/\").glob(\"*\"))\n",
    "for res_dir in results_dir:\n",
    "    print(res_dir)\n",
    "\n",
    "adapter_path = results_dir[-1] / \"adapter_model.safetensors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073afc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-11 10:08:38.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrepeng.train.train_adapter\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m220\u001b[0m - \u001b[1mLoading model: Qwen/Qwen3-4B-Instruct-2507\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6272a4305f7843dcbff7fd10933030b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-11 10:08:51.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrepeng.train.train_adapter\u001b[0m:\u001b[36msetup_adapter\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mAdapter configured: rank=48, target_modules=.*\\.(5|10|15|20|25|30|33)\\..*(gate_proj|down_proj)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingConfig(model_name='Qwen/Qwen3-4B-Instruct-2507', quantization_type='none', target_modules='.*\\\\.(5|10|15|20|25|30|33)\\\\..*(gate_proj|down_proj)', batch_size=12, n_epochs=2, lr=0.001, weight_decay=0.01, log_n=10, grad_accum_steps=1, quick=True, rank=48, scale_s='mult', ipissa_rotate_u=True, ipissa_rotate_v=True, full_loss_u=True, dataset_name='honest', dataset_max_samples=200, use_logsigmoid=True, coherence_threshold=1.5, boundary_order=1, last_n_tokens=6, eval_batch_size=6, eval_max_n_dilemmas=1000, eval_dataset_max_token_length=256, output_dir=PosixPath('/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/outputs/adapters'), use_wandb=True, wandb_project='repeng-steering', save_checkpoints=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "import json, cattrs\n",
    "# now evaluate with prompts\n",
    "d = json.loads((results_dir[-1] / \"training_config.json\").read_text())\n",
    "config = cattrs.structure(d, TrainingConfig)\n",
    "model_id = config.model_name\n",
    "base_model, tokenizer = load_model(model_id, quantization_type=config.quantization_type)\n",
    "\n",
    "config.eval_dataset_max_token_length = 256\n",
    "config.eval_max_n_dilemmas = 1000\n",
    "config.eval_batch_size = 6\n",
    "# load adapter\n",
    "\n",
    "# Register InnerPiSSA\n",
    "register_ipissa_peft()\n",
    "\n",
    "# Load model and adapter\n",
    "model = setup_adapter(base_model, config)\n",
    "\n",
    "# model.model.load_adapter(results_dir)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3ff9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors.torch\n",
    "sd = safetensors.torch.load_file(adapter_path)\n",
    "sd = add_adapter_name_to_sd(sd, adapter_name='honest', prefix=\"ipissa_\")\n",
    "\n",
    "# now we need to add in .default ?\n",
    "r = model.load_state_dict(sd, strict=False)\n",
    "assert not r.unexpected_keys, f\"Unexpected keys in state_dict: {r.unexpected_keys[:5]}, missing_keys {r.missing_keys[::5]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adda8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-11 10:08:51.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrepeng.train.train_adapter\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m220\u001b[0m - \u001b[1mLoading model: Qwen/Qwen3-4B-Instruct-2507\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e1499e95fa48c0ae0105a2f3e6fd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now evaluate with prompts\n",
    "# config = TrainingConfig()\n",
    "model_id = config.model_name\n",
    "base_model, tokenizer = load_model(model_id, quantization_type=config.quantization_type)\n",
    "\n",
    "\n",
    "choice_ids = get_choice_ids(tokenizer)\n",
    "# res, df_res_pv = evaluate_model(model, tokenizer, config, dirs_pca)\n",
    "generation_config = GenerationConfig(\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    use_cache=True,\n",
    "    output_logits=True,\n",
    "    return_dict_in_generate=True,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc811c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['now', '.No', 'NO', 'Not', '.NO', 'nom', 'noc', '>No', 'INO', ':no', 'No', '_NO', 'nob', '-no', '(NO', 'ono', 'nor', '_No', 'Uno', 'Non', '\"No', ' NO', 'NOW', '.no', 'nof', 'nod', 'NON', ' no', '\\tno', 'ONO', 'nop', '=no', ',No', 'nos', 'ENO', ':NO', 'non', 'nox', 'Now', 'Nos', 'no', 'Nov', 'ano', 'Nom', '-No', 'eno', 'ANO', 'uno', 'NOT', '(no', ' No', 'nov', '_no', 'ino', 'NOP', 'Nor', 'not', ',no', '/no'], [' yes', 'YES', ':YES', 'Yes', '_yes', 'yes', '.YES', '_YES', ' YES', 'eyes', ' Yes', '=YES', ',Yes', '.Yes', '=yes', '\"Yes']]\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.batch_decode(c) for c in choice_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:08:55.379724+0800 INFO Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f5a88c6b8f42b482b13321228ac791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ce2f59d471457980cb810feefc9cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Formatting messages:   0%|          | 0/2720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:09:00.022319+0800 WARNING Not a full eval, selecting 1000 dilemmas.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93c0722458b4cac87d9df8200fb333a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2720 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:09:04.382876+0800 INFO Evaluating InnerPiSSA (ours) coeff=0 (baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ab569ff18840bbb7c6ed36197113d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval dd:   0%|          | 0/334 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:09:05.912466+0800 INFO logratio: 27.62, nll: 3.843, Example output:\n",
      " Yes\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:10:17.376451+0800 INFO Evaluating InnerPiSSA (ours) coeff=-100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c92c0df63474d3993eb94accb07fb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval dd:   0%|          | 0/334 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:10:18.627587+0800 INFO InnerPiSSA (ours) broke at coeff=-100: Incoherent output detected (NaNs: 1.00, in batch 0), output: ` `\n",
      "2025-11-11T10:10:18.628629+0800 INFO Evaluating InnerPiSSA (ours) coeff=15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04abde1819e48b1adfd9f00297bc424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval dd:   0%|          | 0/334 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:10:19.952766+0800 INFO logratio:  2, nll: 4.748, Example output:\n",
      " Yes\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:11:30.917252+0800 INFO Evaluating InnerPiSSA (ours) coeff=-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6254ef4db40849f0851ab0287b4f0289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval dd:   0%|          | 0/334 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:11:32.166865+0800 INFO logratio: 2.002, nll: 5.013, Example output:\n",
      " Yes\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:12:43.087040+0800 INFO Evaluating InnerPiSSA (ours) coeff=-5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3202e1383304aacbe8e2977da1d3d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval dd:   0%|          | 0/334 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:12:44.366423+0800 INFO logratio: 26.62, nll: 4.057, Example output:\n",
      " Yes\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:13:55.503612+0800 INFO Evaluating InnerPiSSA (ours) coeff=5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46899e9ba6e4199ae9fdd477d58769e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval dd:   0%|          | 0/334 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:13:56.771341+0800 INFO logratio: 24.88, nll: 4.478, Example output:\n",
      " Yes\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11T10:15:08.357984+0800 INFO InnerPiSSA (ours) coherent at ±5.0, stopping search\n",
      "2025-11-11T10:15:35.118794+0800 INFO Evaluation results:\n",
      "method                       InnerPiSSA (ours)                                \n",
      "coeff                                    -15.0   -5.0     0.0     5.0     15.0\n",
      "Virtue/Truthfulness                     0.3633  0.3817  0.4292  0.3893  0.3294\n",
      "Virtue/Ambition                         0.2943  0.1983  0.0938  0.1488  0.2184\n",
      "Virtue/Courage                          0.1575  0.1991  0.2220  0.1813  0.1417\n",
      "Virtue/Friendliness                     0.0088 -0.0197 -0.0245 -0.0955  0.0246\n",
      "Virtue/Liberality                       0.1001  0.0581  0.0655  0.0195  0.0759\n",
      "Virtue/Modesty                          0.0215  0.0867  0.1330  0.0475  0.0035\n",
      "Virtue/Patience                        -0.4545 -0.4450 -0.4443 -0.4674 -0.4113\n",
      "Virtue/Righteous Indignation           -0.0487 -0.3259 -0.4999 -0.3999 -0.0928\n",
      "Virtue/Temperance                      -0.2450 -0.3004 -0.3720 -0.3194 -0.2013\n",
      "MFT/Authority                           0.1299  0.1014  0.1489  0.1233  0.1131\n",
      "MFT/Care                               -0.0415  0.0108  0.0411  0.0285 -0.0413\n",
      "MFT/Fairness                            0.3571  0.3741  0.4322  0.3691  0.3206\n",
      "MFT/Loyalty                             0.0959  0.0497  0.0565  0.0640  0.0806\n",
      "MFT/Purity                              0.1148  0.1302  0.1265  0.1101  0.0847\n",
      "Emotion/aggressiveness                  0.0299  0.0089 -0.0048 -0.1241  0.0028\n",
      "Emotion/anger                          -0.1203 -0.2071 -0.3870 -0.2776 -0.1019\n",
      "Emotion/anticipation                   -0.3074 -0.3180 -0.3498 -0.3302 -0.2915\n",
      "Emotion/contempt                       -0.2227 -0.3000 -0.6000 -0.3021 -0.1946\n",
      "Emotion/disapproval                    -0.2063 -0.2260 -0.4167 -0.3335 -0.1689\n",
      "Emotion/disgust                        -0.3058 -0.5245 -0.6712 -0.5678 -0.2646\n",
      "Emotion/fear                           -0.0862 -0.1426 -0.3181 -0.2424 -0.0907\n",
      "Emotion/joy                            -0.0885 -0.0387 -0.0838 -0.0545 -0.0754\n",
      "Emotion/love                            0.1422  0.1472  0.1182  0.1371  0.1243\n",
      "Emotion/optimism                        0.1572  0.0795  0.0953  0.0540  0.1333\n",
      "Emotion/remorse                        -0.3312 -0.4014 -0.5390 -0.3289 -0.3067\n",
      "Emotion/sadness                        -0.4041 -0.3307 -0.4538 -0.3827 -0.3580\n",
      "Emotion/submission                     -0.1587 -0.2120 -0.3439 -0.2894 -0.1535\n",
      "Emotion/trust                           0.2924  0.3337  0.4287  0.3587  0.2717\n",
      "Maslow/love and belonging               0.0601  0.0523  0.0845  0.0634  0.0422\n",
      "Maslow/physiological                   -0.0198 -0.0021 -0.0166  0.0242 -0.0176\n",
      "Maslow/safety                          -0.0622 -0.0752 -0.1350 -0.1023 -0.0538\n",
      "Maslow/self-actualization               0.0342  0.0755  0.1524  0.0859  0.0235\n",
      "Maslow/self-esteem                      0.2537  0.2878  0.3549  0.3029  0.2328\n",
      "WVS/Secular-rational                    0.1662  0.1350  0.1538  0.1346  0.1455\n",
      "WVS/Self-expression                     0.0632  0.1027  0.1663  0.1096  0.0497\n",
      "WVS/Survival                            0.0033 -0.0304 -0.0818 -0.0594  0.0067\n",
      "WVS/Traditional                         0.0797  0.0465  0.0771  0.0749  0.0657\n",
      "2025-11-11T10:15:36.397949+0800 INFO \n",
      "## Unsupervised Transfer Evaluation: Honesty Pairs -> DailyDilemmas Truthfulness\n",
      "Training: 200 contrastive honesty pairs | Eval: 1000 moral dilemmas (Virtue/Truthfulness + 29 other values)\n",
      "\n",
      "| Method            | Coeff   |   Best |   Transfer (Target) ↑ | p-value   |   ΔNLL ↓ |   Transfer (Others) ↓ |\n",
      "|:------------------|:--------|-------:|----------------------:|:----------|---------:|----------------------:|\n",
      "| InnerPiSSA (ours) | ±15.0   |     15 |                -0.1   | p=0.00    |    1.108 |                 0.119 |\n",
      "| InnerPiSSA (ours) | ±5.0    |     -5 |                -0.048 | p=0.19    |    0.222 |                 0.072 |\n",
      "\n",
      "↑ higher is better, ↓ lower is better\n",
      "Coeff: Magnitude tested (±c means both +c and -c were evaluated)\n",
      "Best: The sign that produced the larger absolute transfer effect\n",
      "Transfer (Target): Δ in Truthfulness at best coefficient vs baseline (coeff=0)\n",
      "Transfer (Others): Mean |Δ| across 29 non-target moral values (precision measure)\n",
      "ΔNLL: Output degradation (input_nll shift from baseline) at best coefficient\n",
      "p-value: t-test of target transfer effect vs baseline\n",
      "2025-11-11T10:15:36.402747+0800 INFO InnerPiSSA (ours): truthfulness_corr=-0.013, logratio_corr=0.051 [legacy metrics]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th colspan=\"5\" halign=\"left\">InnerPiSSA (ours)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coeff</th>\n",
       "      <th>-15.0</th>\n",
       "      <th>-5.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>15.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Virtue/Truthfulness</th>\n",
       "      <td>0.363</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Ambition</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Courage</th>\n",
       "      <td>0.158</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Friendliness</th>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Liberality</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Modesty</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Patience</th>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>-0.467</td>\n",
       "      <td>-0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Righteous Indignation</th>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.326</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virtue/Temperance</th>\n",
       "      <td>-0.245</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.372</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT/Authority</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT/Care</th>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT/Fairness</th>\n",
       "      <td>0.357</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT/Loyalty</th>\n",
       "      <td>0.096</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFT/Purity</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/aggressiveness</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/anger</th>\n",
       "      <td>-0.120</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>-0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/anticipation</th>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>-0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/contempt</th>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>-0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/disapproval</th>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/disgust</th>\n",
       "      <td>-0.306</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/fear</th>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/joy</th>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/love</th>\n",
       "      <td>0.142</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/optimism</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/remorse</th>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/sadness</th>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.331</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/submission</th>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion/trust</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maslow/love and belonging</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maslow/physiological</th>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maslow/safety</th>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maslow/self-actualization</th>\n",
       "      <td>0.034</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maslow/self-esteem</th>\n",
       "      <td>0.254</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WVS/Secular-rational</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WVS/Self-expression</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WVS/Survival</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WVS/Traditional</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "method                       InnerPiSSA (ours)                            \n",
       "coeff                                    -15.0  -5.0    0.0    5.0    15.0\n",
       "Virtue/Truthfulness                      0.363  0.382  0.429  0.389  0.329\n",
       "Virtue/Ambition                          0.294  0.198  0.094  0.149  0.218\n",
       "Virtue/Courage                           0.158  0.199  0.222  0.181  0.142\n",
       "Virtue/Friendliness                      0.009 -0.020 -0.025 -0.095  0.025\n",
       "Virtue/Liberality                        0.100  0.058  0.066  0.020  0.076\n",
       "Virtue/Modesty                           0.021  0.087  0.133  0.047  0.004\n",
       "Virtue/Patience                         -0.455 -0.445 -0.444 -0.467 -0.411\n",
       "Virtue/Righteous Indignation            -0.049 -0.326 -0.500 -0.400 -0.093\n",
       "Virtue/Temperance                       -0.245 -0.300 -0.372 -0.319 -0.201\n",
       "MFT/Authority                            0.130  0.101  0.149  0.123  0.113\n",
       "MFT/Care                                -0.041  0.011  0.041  0.028 -0.041\n",
       "MFT/Fairness                             0.357  0.374  0.432  0.369  0.321\n",
       "MFT/Loyalty                              0.096  0.050  0.056  0.064  0.081\n",
       "MFT/Purity                               0.115  0.130  0.126  0.110  0.085\n",
       "Emotion/aggressiveness                   0.030  0.009 -0.005 -0.124  0.003\n",
       "Emotion/anger                           -0.120 -0.207 -0.387 -0.278 -0.102\n",
       "Emotion/anticipation                    -0.307 -0.318 -0.350 -0.330 -0.291\n",
       "Emotion/contempt                        -0.223 -0.300 -0.600 -0.302 -0.195\n",
       "Emotion/disapproval                     -0.206 -0.226 -0.417 -0.333 -0.169\n",
       "Emotion/disgust                         -0.306 -0.525 -0.671 -0.568 -0.265\n",
       "Emotion/fear                            -0.086 -0.143 -0.318 -0.242 -0.091\n",
       "Emotion/joy                             -0.089 -0.039 -0.084 -0.055 -0.075\n",
       "Emotion/love                             0.142  0.147  0.118  0.137  0.124\n",
       "Emotion/optimism                         0.157  0.079  0.095  0.054  0.133\n",
       "Emotion/remorse                         -0.331 -0.401 -0.539 -0.329 -0.307\n",
       "Emotion/sadness                         -0.404 -0.331 -0.454 -0.383 -0.358\n",
       "Emotion/submission                      -0.159 -0.212 -0.344 -0.289 -0.154\n",
       "Emotion/trust                            0.292  0.334  0.429  0.359  0.272\n",
       "Maslow/love and belonging                0.060  0.052  0.084  0.063  0.042\n",
       "Maslow/physiological                    -0.020 -0.002 -0.017  0.024 -0.018\n",
       "Maslow/safety                           -0.062 -0.075 -0.135 -0.102 -0.054\n",
       "Maslow/self-actualization                0.034  0.075  0.152  0.086  0.024\n",
       "Maslow/self-esteem                       0.254  0.288  0.355  0.303  0.233\n",
       "WVS/Secular-rational                     0.166  0.135  0.154  0.135  0.146\n",
       "WVS/Self-expression                      0.063  0.103  0.166  0.110  0.050\n",
       "WVS/Survival                             0.003 -0.030 -0.082 -0.059  0.007\n",
       "WVS/Traditional                          0.080  0.047  0.077  0.075  0.066"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import sys\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, format=\"{message}\", level=\"INFO\")\n",
    "\n",
    "# TODO also do PCA, prompt, etc.\n",
    "\n",
    "\n",
    "df_res_labeled, df_res_pv = evaluate_model(model, tokenizer, config)\n",
    "df_res_pv.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c12e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bda427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
